---
title: "STSCI 5740 Final Project"
output: html_document
date: "2023-04-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(tidyverse)
library(randomForest)
library(leaps)
library(glmnet)

data <- read_csv("redone_data_analysis6.csv")

```

```{r}
# LASSO REGRESSION WITH ALL PREDICTORS (sparse matrix with lots of 0's and high dimensional/lots of columns b/c of dummy variables)
# WITH TRAIN/TEST SPLIT
cleaned_data <- data[,!names(data) %in% c("Salary.Range.From")] %>% na.omit

data_X <- model.matrix(Salary.Range.To ~ ., data=cleaned_data)
data_Y = cleaned_data$Salary.Range.To

# TRAIN TEST SPLIT
sample <- sample(c(TRUE, FALSE), nrow(data_X), replace=TRUE, prob=c(0.7,0.3))
train_X  <- data_X[sample, ]
test_X   <- data_X[!sample, ]

train_Y = data_Y[sample]
test_Y = data_Y[!sample]



set.seed(1)
cv.out=cv.glmnet(train_X,train_Y,alpha=1) #10 fold cross validation
bestlam=cv.out$lambda.min
bestlam
lasso.mod=glmnet(train_X,train_Y,alpha=1,lambda=bestlam)
# lasso.coef=coef(lasso.mod)[,1]
# lasso.coef[lasso.coef!=0]
# lasso.coef[lasso.coef==0]

y_predicted <- predict(lasso.mod, s = bestlam, newx = test_X)


# for calculating R-squared value https://www.statology.org/lasso-regression-in-r/
#find SST and SSE
sst <- sum((test_Y - mean(test_Y))^2)
sse <- sum((y_predicted - test_Y)^2)

#find R-Squared
r_2 <- 1 - sse/sst
r_2

plot.new()
plot(test_Y, y_predicted)
abline(a = 0, b = 1)

```

